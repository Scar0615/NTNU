{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">YOLO v5 in PyTorch</h1>\n",
    "<p style=\"text-align:center\">\n",
    "<a href=\"https://pytorch.org/hub/ultralytics_yolov5/\">https://pytorch.org/hub/ultralytics_yolov5/</a>\n",
    "</p>\n",
    "<p><img src=\"model_comparison.png\" width=\"500\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>安裝其它必備的工具模組（確認版本）</h3>\n",
    "<p><a href=\"requirements.txt\">requirements.txt</a>（修正後 windows 版本，<span style=\"color:red\">請自行複製使用</span>）</p>\n",
    "<p>來自\n",
    "    <a href=\"https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt\">\n",
    "    https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt</a>，<br>\n",
    "    但是，pycocotools 改為 pycocotools-windows（windows 版本的模組名稱不同）\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\">pip install -r requirements.txt</p>\n",
    "<p>requirements.txt 內容</p>\n",
    "<pre>\n",
    "<span style=\"color:green\"># base ----------------------------------------</span>\n",
    "matplotlib>=3.2.2\n",
    "numpy>=1.18.5\n",
    "opencv-python>=4.1.2\n",
    "Pillow\n",
    "PyYAML>=5.3.1\n",
    "scipy>=1.4.1\n",
    "torch>=1.7.0\n",
    "torchvision>=0.8.1\n",
    "tqdm>=4.41.0\n",
    "</pre>\n",
    "<pre>\n",
    "<span style=\"color:green\"># logging -------------------------------------</span>\n",
    "tensorboard>=2.4.1\n",
    "# wandb\n",
    "</pre>\n",
    "<pre>\n",
    "<span style=\"color:green\"># plotting ------------------------------------</span>\n",
    "seaborn>=0.11.0\n",
    "pandas\n",
    "</pre>\n",
    "<pre>\n",
    "<span style=\"color:green\"># export --------------------------------------</span>\n",
    "# coremltools>=4.1\n",
    "# onnx>=1.9.0\n",
    "# scikit-learn==0.19.2  # for coreml quantization\n",
    "</pre>\n",
    "<pre>\n",
    "<span style=\"color:green\"># extras --------------------------------------</span>\n",
    "# Cython  # for pycocotools https://github.com/cocodataset/cocoapi/issues/172\n",
    "pycocotools-windows>=2.0  # COCO mAP（pip install pycocotools-windows）\n",
    "thop  # FLOPS computation\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>訓練資料集：COCO Dataset</h3>\n",
    "<pre>\n",
    "<a href=\"https://cocodataset.org/\">https://cocodataset.org/</a>\n",
    "</pre>\n",
    "<p>Class Names:</p>\n",
    "<pre>\n",
    "<b style=\"color:red\">0 - 9</b>\n",
    "person\n",
    "bicycle\n",
    "car\n",
    "motorbike\n",
    "aeroplane\n",
    "bus\n",
    "train\n",
    "truck\n",
    "boat\n",
    "traffic light\n",
    "<b style=\"color:red\">10 - 19</b>\n",
    "fire hydrant\n",
    "stop sign\n",
    "parking meter\n",
    "bench\n",
    "bird\n",
    "cat\n",
    "dog\n",
    "horse\n",
    "sheep\n",
    "cow\n",
    "<b style=\"color:red\">20 - 29</b>\n",
    "elephant\n",
    "bear\n",
    "zebra\n",
    "giraffe\n",
    "backpack\n",
    "umbrella\n",
    "handbag\n",
    "tie\n",
    "suitcase\n",
    "frisbee\n",
    "<b style=\"color:red\">30 - 39</b>\n",
    "skis\n",
    "snowboard\n",
    "sports ball\n",
    "kite\n",
    "baseball bat\n",
    "baseball glove\n",
    "skateboard\n",
    "surfboard\n",
    "tennis racket\n",
    "bottle\n",
    "<b style=\"color:red\">40 - 49</b>\n",
    "wine glass\n",
    "cup\n",
    "fork\n",
    "knife\n",
    "spoon\n",
    "bowl\n",
    "banana\n",
    "apple\n",
    "sandwich\n",
    "orange\n",
    "<b style=\"color:red\">50 - 59</b>\n",
    "broccoli\n",
    "carrot\n",
    "hot dog\n",
    "pizza\n",
    "donut\n",
    "cake\n",
    "chair\n",
    "sofa\n",
    "pottedplant\n",
    "bed\n",
    "<b style=\"color:red\">60 - 69</b>\n",
    "diningtable\n",
    "toilet\n",
    "tvmonitor\n",
    "laptop\n",
    "mouse\n",
    "remote\n",
    "keyboard\n",
    "cell phone\n",
    "microwave\n",
    "oven\n",
    "<b style=\"color:red\">70 - 79</b>\n",
    "toaster\n",
    "sink\n",
    "refrigerator\n",
    "book\n",
    "clock\n",
    "vase\n",
    "scissors\n",
    "teddy bear\n",
    "hair drier\n",
    "toothbrush\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>YOLOv5 PyTorch Hub Tutorial</h3>\n",
    "<p><a href=\"https://github.com/ultralytics/yolov5/issues/36\">YOLOv5 PyTorch Hub Tutorial</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入訓練後模型（s、m、l、x）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入訓練後模型\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>批次影像測試範例</h3>\n",
    "<p>輸入影像名稱串列</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批次測試範例\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
    "\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>單一影像測試範例</h3>\n",
    "<p>輸入單一影像名稱</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 單一測試範例\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
    "\n",
    "# Images\n",
    "fname = 'https://ultralytics.com/images/zidane.jpg'\n",
    "\n",
    "# Inference\n",
    "results = model(fname)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
    "\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>不同模型物體偵測結果比較</h3>\n",
    "<p>單一影像測試，輸入影像檔案名稱</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 讀取影像檔案測試\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model_s = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model_x = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['coffee.jpg']\n",
    "\n",
    "# Inference\n",
    "results_s = model_s(imgs)\n",
    "results_x = model_x(imgs)\n",
    "\n",
    "# Results\n",
    "results_s.print()\n",
    "results_x.print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_x.xyxy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>OpenCV 單一影像測試範例</h3>\n",
    "<p>輸入 OpenCV 單一影像 numpy 陣列（ndarray）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 單一影像測試範例\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "img = cv2.imread('coffee.jpg')\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "results.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>OpenCV 單一影像 YOLO 偵測與結果顯示</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 單一影像 YOLO 偵測與結果顯示\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
    "\n",
    "img = cv2.imread('coffee.jpg')\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "# results.print()\n",
    "\n",
    "# coco_names.txt\n",
    "with open('coco_names.txt', \"r\") as fp:\n",
    "    txt = fp.read()\n",
    "fp.close()\n",
    "coco_names = txt.split('\\n')\n",
    "# print(coco_names)\n",
    "\n",
    "lst = results.xyxy[0].tolist()\n",
    "for u in lst:\n",
    "    x, y, w, h = u[0], u[1], u[2], u[3]\n",
    "    p = u[4]\n",
    "    i = int(u[-1])\n",
    "    name = coco_names[i]\n",
    "    t = 'Class[%2d] = %-16s, Loc=( %6.1f, %6.1f, %6.1f, %6.1f), p = %5.3f' % (i,name, x, y, w, h, p)\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>OpenCV 單一影像 YOLO 偵測與結果標籤繪製顯示</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 單一影像 YOLO 偵測與結果標籤繪製顯示\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 載入 YOLO 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)\n",
    "\n",
    "# 讀入測試影像\n",
    "img = cv2.imread('coffee.jpg')\n",
    "\n",
    "# 物體偵測\n",
    "results = model(img)\n",
    "\n",
    "# 讀取 COCO 類別名稱檔案\n",
    "# coco_names.txt\n",
    "with open('coco_names.txt', \"r\") as fp:\n",
    "    txt = fp.read()\n",
    "fp.close()\n",
    "coco_names = txt.split('\\n')\n",
    "\n",
    "# 設定物體類別色彩\n",
    "coco_colors = []\n",
    "for i in range(len(coco_names)):\n",
    "    c = (int(np.random.randint(0,255)), int(np.random.randint(0,255)), int(np.random.randint(0,255)))\n",
    "    coco_colors.append(c)\n",
    "\n",
    "# 繪製偵測結果\n",
    "lst = results.xyxy[0].tolist()\n",
    "for u in lst:\n",
    "    x0, y0, w, h = int(u[0]), int(u[1]), int(u[2]), int(u[3])\n",
    "    x1, y1 = x0 + w, y0 + h\n",
    "    p = u[4]\n",
    "    i = int(u[-1])\n",
    "    # 框線與標籤訊息\n",
    "    name = coco_names[i]\n",
    "    label = '%s %6.4f' % (name, p)\n",
    "    c = coco_colors[i]\n",
    "    if (p > 0.5):\n",
    "        # 繪製物體框線\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color=c, thickness=2)\n",
    "        # 預估標籤尺寸\n",
    "        ((lw, lh), _) = cv2.getTextSize(label, fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, thickness=2)\n",
    "        tw, th = int(x0 + lw * 1.05), int(y0 + lh * 1.25)\n",
    "        # 繪製標籤\n",
    "        cv2.rectangle(img, (x0, y0), (tw, th), color=c, thickness=cv2.FILLED)\n",
    "        # 繪製標籤文字\n",
    "        cv2.putText(img, label, org=(x0, th), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, color=(255,255,255), thickness=2)\n",
    "\n",
    "# 顯示數據結果（pandas）\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
    "\n",
    "# 儲存偵測後的結果影像（含框線與標籤）\n",
    "cv2.imwrite('coffee_detected.jpg', img)\n",
    "\n",
    "# 顯示偵測結果（含框線與標籤之影像）\n",
    "cv2.imshow('YOLO', img)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>OpenCV 視訊即時偵測與顯示結果</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 視訊即時偵測與顯示結果\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 載入 YOLO 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# 讀取 COCO 類別名稱檔案\n",
    "# coco_names.txt\n",
    "with open('coco_names.txt', \"r\") as fp:\n",
    "    txt = fp.read()\n",
    "fp.close()\n",
    "coco_names = txt.split('\\n')\n",
    "\n",
    "# 設定物體類別色彩\n",
    "coco_colors = []\n",
    "for i in range(len(coco_names)):\n",
    "    c = (int(np.random.randint(0,255)), int(np.random.randint(0,255)), int(np.random.randint(0,255)))\n",
    "    coco_colors.append(c)\n",
    "\n",
    "# 利用 cv2.VideoCapture 連線視訊攝影機\n",
    "cap = cv2.VideoCapture(0) # 編號 0，系統預設攝影機\n",
    "\n",
    "while (True):\n",
    "    # 擷取視訊畫面\n",
    "    ret, frame = cap.read()\n",
    "    # 若成功擷取畫面（frame），則進行 YOLO 物體偵測\n",
    "    if (ret == True):\n",
    "        results = model(frame)\n",
    "        # 顯示結果\n",
    "        lst = results.xyxy[0].tolist()\n",
    "        for u in lst:\n",
    "            x0, y0, w, h = int(u[0]), int(u[1]), int(u[2]), int(u[3])\n",
    "            x1, y1 = x0 + w, y0 + h\n",
    "            p = u[4]\n",
    "            i = int(u[-1])\n",
    "            # 框線與標籤訊息\n",
    "            label = '%s %6.4f' % (coco_names[i], p)\n",
    "            c = coco_colors[i]\n",
    "            if (p > 0.4):\n",
    "                # 物體框線\n",
    "                cv2.rectangle(frame, (x0, y0), (x1, y1), color=c, thickness=2)\n",
    "                # 預估標籤尺寸\n",
    "                ((lw, lh), _) = cv2.getTextSize(label, fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, thickness=2)\n",
    "                tw, th = int(x0 + lw * 1.05), int(y0 + lh * 1.25)\n",
    "                # 繪製標籤\n",
    "                cv2.rectangle(frame, (x0, y0), (tw, th), color=c, thickness=cv2.FILLED)\n",
    "                # 繪製標籤文字\n",
    "                cv2.putText(frame, label, org=(x0, th), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, color=(255,255,255), thickness=2)\n",
    "        # 顯示偵測結果\n",
    "        cv2.imshow('YOLO', frame)\n",
    "    if (cv2.waitKey(25) == ord(' ')):\n",
    "        break\n",
    "\n",
    "# 釋放視訊擷取所佔用的記憶體\n",
    "cap.release()\n",
    " \n",
    "# 關閉所有顯示視窗\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
