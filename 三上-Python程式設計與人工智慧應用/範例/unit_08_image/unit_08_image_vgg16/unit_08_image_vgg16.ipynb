{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">VGG16 Image Recognition（CIFAR-1000 物件）</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<table>\n",
    "    <tr>\n",
    "    <td><img src=\"https://www.hibiscusgarden.com/wp-content/uploads/2017/12/pina.jpg\" width=\"300\"></td>\n",
    "    <td><img src=\"https://cdn.shopify.com/s/files/1/0267/7948/4355/articles/88f44c1d5f09f8eb01b557ad014b743d_600x.jpg\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<pre>\n",
    "上圖取自\n",
    "<a href=\"https://cdn.shopify.com/s/files/1/0267/7948/4355/articles/88f44c1d5f09f8eb01b557ad014b743d_600x.jpg\">https://cdn.shopify.com/s/files/1/0267/7948/4355/articles/88f44c1d5f09f8eb01b557ad014b743d_600x.jpg</a>\n",
    "<a href=\"https://www.hibiscusgarden.com/wp-content/uploads/2017/12/pina.jpg\">https://www.hibiscusgarden.com/wp-content/uploads/2017/12/pina.jpg</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>CIFAR-1000 class names（物體類別名稱）from ImageNet</h3>\n",
    "<pre>\n",
    "<a href=\"https://github.com/xmartlabs/caffeflow/blob/master/examples/imagenet/imagenet-classes.txt\">imagenet_classes.txt</a>\n",
    "pineapple (class index = 953)\n",
    "banana (class index = 954)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入 CIFAR-1000 物體類別名稱</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 CIFAR-1000 物體類別名稱\n",
    "\n",
    "with open('imagenet_classes.txt', 'r') as fp:\n",
    "    txt = fp.read()\n",
    "fp.close()\n",
    "\n",
    "class_names = txt.split('\\n')\n",
    "\n",
    "print(class_names[950:960])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入 VGG16 Model</h3>\n",
    "<p>下載至個人根目錄下</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 VGG16 Model\n",
    "\n",
    "import torch\n",
    "\n",
    "# 下載\n",
    "vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "\n",
    "# ANN 網路模型執行（原定義啟用）\n",
    "vgg16.eval()\n",
    "\n",
    "# 顯示定義\n",
    "print(vgg16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>其它 VGG 變形</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg variants\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg11', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg11_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg13', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg13_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19_bn', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Image Pre-Processing 定義</h3>\n",
    "<p>torchvision 工具模組的 transforms 功能預設使用 Image 工具模組的影像格式</p>\n",
    "<pre>\n",
    "影像轉為 Tensor 格式（shape: 3,224,224）\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Pre-Processing 定義\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Image 讀取測試影像＆顯示</h3>\n",
    "<p>Image Pre-processing 後成為 Tensor</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 讀取測試影像＆顯示\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open('pineapple.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_tensor = preprocess(img)\n",
    "\n",
    "print(img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>OpenCV 讀取測試影像</h3>\n",
    "<p>Image Pre-processing 後成為 Tensor</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_cv2 = cv2.imread('pineapple.jpg')\n",
    "\n",
    "cv2.imshow('VGG16', img_cv2)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# OpenCV to Image 格式轉換\n",
    "img_cv2 = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "img = Image.fromarray(img_cv2)\n",
    "\n",
    "img_tensor = preprocess(img)\n",
    "\n",
    "print(img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>準備好 VGG16 所需的 Tensor 格式（n, 3, 224, 224）</h3>\n",
    "<p>n 是影像數（目前 n = 1）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備好 VGG16 所需的 Tensor 格式（n, 3, 224, 224）\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.zeros(1, 3, 224, 224)\n",
    "\n",
    "x[0] = img_tensor\n",
    "\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>VGG16 辨識</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 辨識\n",
    "\n",
    "import torch\n",
    "\n",
    "output = vgg16(x)\n",
    "\n",
    "lst = output[0].tolist()\n",
    "idx = lst.index(max(lst))\n",
    "\n",
    "print('class index = ', idx)\n",
    "print('class name  = ', class_names[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:orange\">VGG16 影像辨識（整合版）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 影像辨識（整合版）\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 載入 CIFAR-1000 物體類別名稱\n",
    "\n",
    "with open('imagenet_classes.txt', 'r') as fp:\n",
    "    txt = fp.read()\n",
    "fp.close()\n",
    "class_names = txt.split('\\n')\n",
    "\n",
    "# 載入 VGG16 Model\n",
    "\n",
    "# 下載\n",
    "vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "\n",
    "# ANN 網路模型執行（原定義啟用）\n",
    "vgg16.eval()\n",
    "\n",
    "# Image Pre-Processing 定義\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n",
    "\n",
    "# Image 讀取測試影像＆顯示\n",
    "\n",
    "img = Image.open('pineapple.jpg')\n",
    "# img = Image.open('banana.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_tensor = preprocess(img)\n",
    "\n",
    "# 準備好 VGG16 所需的 Tensor 格式（n, 3, 224, 224）\n",
    "\n",
    "x = torch.zeros(1, 3, 224, 224)\n",
    "x[0] = img_tensor\n",
    "\n",
    "# VGG16 辨識\n",
    "\n",
    "output = vgg16(x)\n",
    "\n",
    "lst = output[0].tolist()\n",
    "idx = lst.index(max(lst))\n",
    "\n",
    "print('class index = ', idx)\n",
    "print('class name  = ', class_names[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
