{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">VGG16 Transfer Learning</h1>\n",
    "<h3 align=\"center\">CIFAR-1000 VGG16 辨識『蓮霧』、『釋迦』（非 CIFAR-1000 物件）</h3>\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"0.jpg\" width=\"300\"></td>\n",
    "<td><img src=\"1.jpg\" width=\"300\"></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:blue\">準備訓練樣本</h3>\n",
    "<pre>\n",
    "<span style=\"color:red\">0/</span>\n",
    "    Class 0: 蓮霧（wax apple）訓練樣本\n",
    "<span style=\"color:red\">1/</span>\n",
    "    Class 1: 釋迦（sakyamuni）訓練樣本\n",
    "<span style=\"color:red\">u/</span>\n",
    "    測試樣本\n",
    "    0.jpg（蓮霧）\n",
    "    1.jpg（釋迦）\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Image Standardization</h3>\n",
    "<pre>\n",
    "影像樣本：蓮霧 wax apple vs. 釋迦 sakyamuni\n",
    "mean = ( 0.6256207676309048,  0.5443063055210661,  0.4021625197030607  )\n",
    "std  = ( 0.24913299801303207, 0.27146509504783634, 0.29020713784312463 )\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Standardization\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "images_nd = np.zeros([40, 3, 224, 224], dtype=np.float32) # float32 for pytorch tensor\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Class 0\n",
    "files = glob.glob('images/0/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "# Class 1\n",
    "files = glob.glob('images/1/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "mr = np.mean(images_nd[:,0,:,:])\n",
    "mg = np.mean(images_nd[:,1,:,:])\n",
    "mb = np.mean(images_nd[:,2,:,:])\n",
    "\n",
    "sr = np.std(images_nd[:,0,:,:])\n",
    "sg = np.std(images_nd[:,1,:,:])\n",
    "sb = np.std(images_nd[:,2,:,:])\n",
    "    \n",
    "print(mr, mg, mb)\n",
    "print(sr, sg, sb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Image Pre-Processing</h3>\n",
    "<pre>\n",
    "影像轉為 Tensor 格式\n",
    "input_tensor (shape: 40,3,224,224)\n",
    "output_tensor (shape: 40,2)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    transforms.Normalize(mean=[0.626, 0.544, 0.402], std=[0.249, 0.271, 0.290]), # Standardized as Normal(mean,std)\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "images_nd = np.zeros([40, 3, 224, 224], dtype=np.float32) # float32 for pytorch tensor\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Class 0\n",
    "files = glob.glob('images/0/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "# Class 1\n",
    "files = glob.glob('images/1/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "input_tensor = torch.from_numpy(images_nd)\n",
    "print(input_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "labels_nd = np.zeros([40, 2], dtype=np.float32) # float32 for pytorch tensor\n",
    "\n",
    "for i in range(40):\n",
    "    if (i < 20):\n",
    "        labels_nd[i,0], labels_nd[i,1] = 1, 0\n",
    "    else:\n",
    "        labels_nd[i,0], labels_nd[i,1] = 0, 1\n",
    "\n",
    "output_tensor = torch.from_numpy(labels_nd)\n",
    "\n",
    "print(output_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:blue\">建立 VGG16 Model</h3>\n",
    "<hr>\n",
    "<h3>載入 VGG16 Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 載入 VGG16 Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "\n",
    "vgg16.eval()\n",
    "\n",
    "# print(vgg16)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>其它 VGG 變形</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg variants\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg11', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg11_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg13', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg13_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16_bn', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19', pretrained=True)\n",
    "# vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg19_bn', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>調整 Model 符合應用</h3>\n",
    "<p>把最後一層從原本 out=1000 改成 out=2（2-class classification）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整 Model 符合應用\n",
    "# 把最後一層從原本 out=1000 改成 out=2（2-class classification）\n",
    "\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "print(vgg16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Move to GPU</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "# VGG16 模型 Tensor\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# 訓練樣本 Tensors\n",
    "x = input_tensor\n",
    "y = output_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:blue\">VGG16 Transfer Learning</h3>\n",
    "<pre>\n",
    "model: vgg16\n",
    "input: x\n",
    "label: y\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 樣本數 N\n",
    "N = len(x)\n",
    "print('總樣本數：', N)\n",
    "\n",
    "# 訓練回合數\n",
    "EPOCH = 100\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Optimizer\n",
    "# optimizer = optim.SGD(mlp.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCH):\n",
    "    # shuffling\n",
    "    permute = torch.randperm(x.size()[0])\n",
    "    xi = x[permute]\n",
    "    yi = y[permute]\n",
    "    # zero the gradient buffers\n",
    "    optimizer.zero_grad()\n",
    "    # feed foreward\n",
    "    output = vgg16(xi)\n",
    "    # evaluating loss\n",
    "    loss = criterion(output, yi)\n",
    "    # display loss\n",
    "    print('epoch = %8d, loss = %20.12f' % (epoch, loss))\n",
    "    # feed backward\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>儲存訓練後 VGG16 Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存訓練後 VGG16 Model\n",
    "\n",
    "torch.save(vgg16.state_dict(), 'vgg16.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:orange\">VGG16 Transfer Learning（整合版，支援 GPU，方便上計算伺服器訓練）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 Transfer Learning（整合版，支援 GPU）\n",
    "\n",
    "# Image Pre-Processing\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    transforms.Normalize(mean=[0.626, 0.544, 0.402], std=[0.249, 0.271, 0.290]), # Standardized as Normal(mean,std)\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "images_nd = np.zeros([40, 3, 224, 224], dtype=np.float32) # float32 for pytorch tensor\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Class 0\n",
    "files = glob.glob('images/0/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "# Class 1\n",
    "files = glob.glob('images/1/*')\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    images_nd[i] = tsr.numpy()\n",
    "    i = i + 1\n",
    "\n",
    "input_tensor = torch.from_numpy(images_nd)\n",
    "# print(input_tensor.shape)\n",
    "\n",
    "# Labels\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "labels_nd = np.zeros([40, 2], dtype=np.float32) # float32 for pytorch tensor\n",
    "\n",
    "for i in range(40):\n",
    "    if (i < 20):\n",
    "        labels_nd[i,0], labels_nd[i,1] = 1, 0\n",
    "    else:\n",
    "        labels_nd[i,0], labels_nd[i,1] = 0, 1\n",
    "\n",
    "output_tensor = torch.from_numpy(labels_nd)\n",
    "\n",
    "# print(output_tensor)\n",
    "\n",
    "# 載入 VGG16 Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "\n",
    "vgg16.eval()\n",
    "\n",
    "# print(vgg16)\n",
    "# print()\n",
    "\n",
    "# 調整 Model 符合應用\n",
    "# 把最後一層從原本 out=1000 改成 out=2（2-class classification）\n",
    "\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "# print(vgg16)\n",
    "\n",
    "# Move to GPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "# VGG16 模型 Tensor\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# 訓練樣本 Tensors\n",
    "x = input_tensor.to(device)\n",
    "y = output_tensor.to(device)\n",
    "\n",
    "# Transfer Learning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 樣本數 N\n",
    "N = len(x)\n",
    "print('總樣本數：', N)\n",
    "\n",
    "# 訓練回合數\n",
    "EPOCH = 100\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Optimizer\n",
    "# optimizer = optim.SGD(mlp.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCH):\n",
    "    permute = torch.randperm(x.size()[0])\n",
    "    xi = x[permute]\n",
    "    yi = y[permute]\n",
    "    # zero the gradient buffers\n",
    "    optimizer.zero_grad()\n",
    "    # feed foreward\n",
    "    output = vgg16(xi)\n",
    "    # evaluating loss\n",
    "    loss = criterion(output, yi)\n",
    "    # display loss\n",
    "    print('epoch = %8d, loss = %20.12f' % (epoch, loss))\n",
    "    # feed backward\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "# 儲存訓練後 VGG16 Model\n",
    "torch.save(vgg16.state_dict(), 'vgg16.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:blue\">測試驗證</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>定義調整後的 VGG16 模型</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 VGG16 Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vgg16 = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "\n",
    "vgg16.eval()\n",
    "\n",
    "# print(vgg16)\n",
    "# print()\n",
    "\n",
    "# 調整 Model 符合應用\n",
    "# 把最後一層從原本 out=1000 改成 out=2（2-class classification）\n",
    "\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "# print(vgg16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入訓練後 VGG16 Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入訓練後 VGG16 Model\n",
    "\n",
    "vgg16.load_state_dict(torch.load('vgg16.model', map_location='cpu'))\n",
    "vgg16.eval()\n",
    "print('Load previous nn model completely!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>測試</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "\n",
    "# Image Pre-Processing\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 影像 resize 成 256x256\n",
    "    transforms.CenterCrop(224), # 切出中央 224x224\n",
    "    transforms.ToTensor(), # 由 Image 改成 Tensor\n",
    "    transforms.Normalize(mean=[0.626, 0.544, 0.402], std=[0.249, 0.271, 0.290]), # Standardized as Normal(mean,std)\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standardized as Normal(mean,std)\n",
    "])\n",
    "\n",
    "# 載入影像，轉換成 Tensors\n",
    "\n",
    "files = glob.glob('images/u/*')\n",
    "\n",
    "n = len(files)\n",
    "input_tensor = torch.Tensor(n, 3, 224, 224)\n",
    "\n",
    "i = 0\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    tsr = preprocess(img)\n",
    "    input_tensor[i] = tsr\n",
    "    i = i + 1\n",
    "\n",
    "# 批次測試\n",
    "    \n",
    "output = vgg16(input_tensor)\n",
    "\n",
    "probs = torch.nn.functional.softmax(output, dim=0)\n",
    "\n",
    "# print(output.detach())\n",
    "# print(probs.detach())\n",
    "\n",
    "# 顯示結果\n",
    "\n",
    "lst = probs.detach().tolist()\n",
    "for i in range(n):\n",
    "    p0 = lst[i][0]\n",
    "    p1 = lst[i][1]\n",
    "    if (p0 >= p1):\n",
    "        t = 'Class 0 (prob = %5.3f vs. %5.3f): %s' % (p0, p1, files[i])\n",
    "    else:\n",
    "        t = 'Class 1 (prob = %5.3f vs. %5.3f): %s' % (p0, p1, files[i])\n",
    "    print(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
