{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Naive Bayes Classifier for Text Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>情感類別（感知形容詞）：</h3>\n",
    "<pre>\n",
    "'清新', '憂愁', '真誠', '青春', '成熟',\n",
    "'有趣', '無聊', '溫和', '剛強', '科技',\n",
    "'熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "'浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "'舒服', '活潑', '悠閒'\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情感類別（感知形容詞）\n",
    "\n",
    "alst = [\n",
    "    '清新', '憂愁', '真誠', '青春', '成熟',\n",
    "    '有趣', '無聊', '溫和', '剛強', '科技',\n",
    "    '熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "    '浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "    '舒服', '活潑', '悠閒'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入 emo23 的 Likelihood 資料</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230023\n"
     ]
    }
   ],
   "source": [
    "# 載入 emo23 的 Likelihood 資料\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('likelihood_emo23.pkl', 'rb') as fp:\n",
    "    likelihood = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "print(len(likelihood))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>輸入測試文句</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入測試文句\n",
    "\n",
    "txt = '今天心情很好，在社團跟大家玩得很開心，晚上打算去吃大餐，一切都安排得很好。'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "刪除非中文的所有文字與符號\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先刪除非中文的所有文字與符號\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_punctuation(line):\n",
    "    rule = re.compile(r'[^\\u4e00-\\u9fa5|\\s]')\n",
    "    line = rule.sub(' ', line)\n",
    "    return line\n",
    "\n",
    "def remove_redundant_space(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>詞法分析（字詞修整）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天心情很好 在社團跟大家玩得很開心 晚上打算去吃大餐 一切都安排得很好 \n"
     ]
    }
   ],
   "source": [
    "# 詞法分析（字詞修整）\n",
    "\n",
    "txt = remove_punctuation(txt)\n",
    "txt = remove_redundant_space(txt)\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "詞法分析（斷詞）\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\trchou\\Dropbox\\000 teaching\\aisd10a\\jupyter\\unit_09_text\\unit_09_text_naive_bayes_classifier\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\trchou\\AppData\\Local\\Temp\\jieba.ua8b55bb30a5d8be72a6e9488d1c37541.cache\n",
      "Loading model cost 0.903 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天', '心情', '很', '好', ' ', '在', '社團', '跟', '大家', '玩得', '很', '開心', ' ', '晚上', '打算', '去', '吃', '大餐', ' ', '一切', '都', '安排', '得', '很', '好', ' ']\n"
     ]
    }
   ],
   "source": [
    "# 斷詞\n",
    "\n",
    "import jieba\n",
    "\n",
    "# 有必要的話載入斷詞用專屬字典\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.load_userdict('user.txt')\n",
    "\n",
    "res = jieba.cut(txt)\n",
    "\n",
    "lst = [ x for x in res ]\n",
    "\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "刪除虛字『的』等無用字詞（Stopword），過濾單字詞\n",
    "</h3>\n",
    "<pre>\n",
    "Stopword 代表很常見（高頻率）的詞彙，但是，對語意分辨沒有什麼貢獻。\n",
    "<p>詞法分析的最後輸出結果是<span style=\"color:red\">『字符串』（tokens）</span>，作為分類的依據\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天', '心情', '社團', '大家', '玩得', '開心', '晚上', '打算', '大餐', '一切', '安排']\n"
     ]
    }
   ],
   "source": [
    "# 刪除虛字『的』等無用字詞，Stopword\n",
    "\n",
    "# stopword 可以是需要而自行增加\n",
    "stopwords = [ '的', '之', '乎', '者', '也', ' ' ]\n",
    "\n",
    "tokens = []\n",
    "for x in lst:\n",
    "    if (x not in stopwords):\n",
    "        if (len(x) >= 2):\n",
    "            tokens.append(x)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Probability of Likelyhood 模組化函數（prob_likely）的定義</h3>\n",
    "<pre>\n",
    "Prob { w | a } = p = likelyhood[(w,a)]\n",
    "p = 0.???, if w in metaphors of a (note that: a in metaphors of a)\n",
    "p = 0.001, otherwise\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of Likelyhood 模組化函數（prob_likely）的定義\n",
    "\n",
    "alpha = 0.000001\n",
    "\n",
    "def prob_likely(w, a):\n",
    "    try:\n",
    "        p = likelihood[(w,a)]\n",
    "    except:\n",
    "        p = alpha\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<h3>likelihood 函數的運用</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.9999989999999979\n",
      "p1 =  0.0003659794954630224\n",
      "p2 =  1e-06\n"
     ]
    }
   ],
   "source": [
    "# 清新\n",
    "\n",
    "a0 = '有趣'\n",
    "\n",
    "# 累計機率應為 0.999（1-alpha）\n",
    "acc = 0.0\n",
    "for w, a in likelihood:\n",
    "    if (a == a0):\n",
    "        p = prob_likely(w, a)\n",
    "        acc = acc + p\n",
    "print('acc = ', acc)\n",
    "\n",
    "p1 = prob_likely(a0, a0)\n",
    "p2 = prob_likely('烏龜', a0)\n",
    "\n",
    "print('p1 = ', p1)\n",
    "print('p2 = ', p2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>特定詞彙的 Likelihood 測試</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =   0.00012659, p = Prob{ 沒事 | 無聊 }\n",
      "p =   0.00012577, p = Prob{ 沒事 | 舒服 }\n",
      "p =   0.00008879, p = Prob{ 沒事 | 憂愁 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 清新 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 真誠 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 青春 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 成熟 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 有趣 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 溫和 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 剛強 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 科技 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 熱情 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 冷漠 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 正義 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 甜美 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 苦澀 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 浪漫 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 科幻 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 現代 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 陳腐 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 驚悚 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 活潑 }\n",
      "p =   0.00000100, p = Prob{ 沒事 | 悠閒 }\n"
     ]
    }
   ],
   "source": [
    "# 計算 w 對 emo23 所有詞彙的 likelihood\n",
    "\n",
    "w = '沒事'\n",
    "\n",
    "dic = dict()\n",
    "\n",
    "for a in alst:\n",
    "    p = prob_likely(w, a)\n",
    "    dic[a] = p\n",
    "    \n",
    "# 排序，輸出前 20 項 ccom\n",
    "\n",
    "sorted_list = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(sorted_list)\n",
    "\n",
    "for x in sorted_list:\n",
    "    c, p = x[0], x[1]\n",
    "    print('p = %12.8f, p = Prob{ %s | %s }' % (p, w, c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>樸素貝式（Naive Bayes）分類</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天', '心情', '社團', '大家', '玩得', '開心', '晚上', '打算', '大餐', '一切', '安排']\n",
      "有趣: 0.000000000215915116\n",
      "無聊: 0.000000000003032493\n",
      "悠閒: 0.000000000002468391\n",
      "熱情: 0.000000000000931487\n",
      "舒服: 0.000000000000013163\n",
      "浪漫: 0.000000000000000130\n",
      "真誠: 0.000000000000000101\n",
      "活潑: 0.000000000000000071\n",
      "苦澀: 0.000000000000000001\n",
      "清新: 0.000000000000000001\n",
      "青春: 0.000000000000000001\n",
      "甜美: 0.000000000000000001\n",
      "冷漠: 0.000000000000000001\n",
      "成熟: 0.000000000000000001\n",
      "現代: 0.000000000000000000\n",
      "憂愁: 0.000000000000000000\n",
      "正義: 0.000000000000000000\n",
      "陳腐: 0.000000000000000000\n",
      "溫和: 0.000000000000000000\n",
      "剛強: 0.000000000000000000\n",
      "科技: 0.000000000000000000\n",
      "科幻: 0.000000000000000000\n",
      "驚悚: 0.000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# 樸素貝式（Naive Bayes）分類\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "dic = dict()\n",
    "for a in alst:\n",
    "    q = 1\n",
    "    for t in tokens:\n",
    "        p = prob_likely(t, a)\n",
    "        # q = q * p\n",
    "        q = q * p * 10000\n",
    "    dic[a] = q\n",
    "\n",
    "sorted_list = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for x in sorted_list:\n",
    "    a, p = x[0], x[1]\n",
    "    print('%s: %20.18f' % (a, p))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange\">Text Classification based on Naive Bayes Theory（整合版）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\trchou\\Dropbox\\000 teaching\\aisd10a\\jupyter\\unit_09_text\\unit_09_text_naive_bayes_classifier\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\trchou\\AppData\\Local\\Temp\\jieba.ua8b55bb30a5d8be72a6e9488d1c37541.cache\n",
      "Loading model cost 0.916 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Text Classification based on Naive Bayes Theory（整合版）\n",
    "\n",
    "import pickle\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 分類類別\n",
    "\n",
    "alst = [\n",
    "    '清新', '憂愁', '真誠', '青春', '成熟',\n",
    "    '有趣', '無聊', '溫和', '剛強', '科技',\n",
    "    '熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "    '浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "    '舒服', '活潑', '悠閒'\n",
    "]\n",
    "\n",
    "# stopword 可以是需要而自行增加\n",
    "\n",
    "stopwords = [ '的', '之', '乎', '者', '也', ' ' ]\n",
    "\n",
    "# 載入語言模型（word2vec, jieba, ...）函數定義\n",
    "\n",
    "def load_language_model():\n",
    "    # 載入 emo23 的 Likelihood 資料\n",
    "    with open('likelihood_emo23.pkl', 'rb') as fp:\n",
    "        likelihood = pickle.load(fp)\n",
    "    fp.close()\n",
    "    jieba.set_dictionary('dict.txt.big')\n",
    "    jieba.load_userdict('user.txt')\n",
    "    return likelihood\n",
    "\n",
    "# 刪除非中文的所有文字與符號函數定義\n",
    "\n",
    "def remove_non_chinese(line):\n",
    "    # 消除英文文數字\n",
    "    rule = re.compile('[a-zA-Z0-9]')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除特殊符號（含部分全形符號）\n",
    "    rule = re.compile('[’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除不可見字碼\n",
    "    rule = re.compile('[\\001\\002\\003\\004\\005\\006\\007\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除所有全形符號\n",
    "    rule = re.compile('[^\\u4e00-\\u9fa5]')\n",
    "    line = rule.sub(' ', line)\n",
    "    return line\n",
    "\n",
    "def remove_redundant_space(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n",
    "\n",
    "# 詞法分析器函數定義\n",
    "\n",
    "def lexical_analyzer(txt):\n",
    "    # print(txt)\n",
    "    txt = remove_non_chinese(txt)\n",
    "    txt = remove_redundant_space(txt)\n",
    "    res = jieba.cut(txt)\n",
    "    lst = [ x for x in res ]\n",
    "    # print(lst)\n",
    "    tokens = []\n",
    "    for x in lst:\n",
    "        if (x not in stopwords):\n",
    "            if (len(x) >= 2):\n",
    "                tokens.append(x)\n",
    "    # print(tokens)\n",
    "    return tokens\n",
    "\n",
    "# Probability of Likelyhood 模組化函數（prob_likely）的定義\n",
    "\n",
    "alpha = 0.000001\n",
    "\n",
    "def prob_likely(w, a):\n",
    "    try:\n",
    "        p = likelihood[(w,a)]\n",
    "    except:\n",
    "        p = alpha\n",
    "    return p\n",
    "\n",
    "# 文件分類器函數定義\n",
    "\n",
    "def text_classifier(tokens):\n",
    "    # 樸素貝式（Naive Bayes）分類\n",
    "    dic = dict()\n",
    "    for a in alst:\n",
    "        q = 1\n",
    "        for t in tokens:\n",
    "            p = prob_likely(t, a)\n",
    "            # q = q * p\n",
    "            q = q * p * 10000\n",
    "        dic[a] = q\n",
    "    # 字典排序（成為串列）\n",
    "    lst = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "    return lst\n",
    "\n",
    "# 載入語言模型\n",
    "\n",
    "likelihood =  load_language_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>整合測試</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在新的一年裡，希望所有朋友都幸福快樂心想事成！\n",
      "熱情: 0.00011783294370\n",
      "真誠: 0.00009897563048\n",
      "悠閒: 0.00000150008651\n",
      "無聊: 0.00000097769708\n",
      "青春: 0.00000001041810\n",
      "浪漫: 0.00000000945896\n",
      "憂愁: 0.00000000806715\n",
      "甜美: 0.00000000801321\n",
      "有趣: 0.00000000736224\n",
      "冷漠: 0.00000000670429\n",
      "正義: 0.00000000010392\n",
      "苦澀: 0.00000000009002\n",
      "清新: 0.00000000008542\n",
      "活潑: 0.00000000008512\n",
      "舒服: 0.00000000008360\n",
      "驚悚: 0.00000000008047\n",
      "溫和: 0.00000000007678\n",
      "成熟: 0.00000000000100\n",
      "剛強: 0.00000000000100\n",
      "科技: 0.00000000000100\n",
      "科幻: 0.00000000000100\n",
      "現代: 0.00000000000100\n",
      "陳腐: 0.00000000000100\n"
     ]
    }
   ],
   "source": [
    "# 整合測試\n",
    "\n",
    "# 輸入\n",
    "\n",
    "# 測試例句\n",
    "# txt = '不在乎天長地久，只在乎曾經擁有'\n",
    "# txt = '實踐是檢驗真理的唯一方法。'\n",
    "txt = '在新的一年裡，希望所有朋友都幸福快樂心想事成！'\n",
    "\n",
    "# 文件分類\n",
    "\n",
    "tokens = lexical_analyzer(txt)\n",
    "result = text_classifier(tokens)\n",
    "\n",
    "# 顯示結果\n",
    "\n",
    "print(txt)\n",
    "for a, score in result:\n",
    "    print('%s: %16.14f' % (a, score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
