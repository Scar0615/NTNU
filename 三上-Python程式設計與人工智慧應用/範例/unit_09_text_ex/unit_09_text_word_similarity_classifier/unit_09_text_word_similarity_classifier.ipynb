{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Word Similarity Classifier for Text Classification</h1>\n",
    "<h3 align=\"center\">based on similarity from word2vec</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>情感類別（感知形容詞）：</h3>\n",
    "<pre>\n",
    "'清新', '憂愁', '真誠', '青春', '成熟',\n",
    "'有趣', '無聊', '溫和', '剛強', '科技',\n",
    "'熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "'浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "'舒服', '活潑', '悠閒'\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "alst = [\n",
    "    '清新', '憂愁', '真誠', '青春', '成熟',\n",
    "    '有趣', '無聊', '溫和', '剛強', '科技',\n",
    "    '熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "    '浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "    '舒服', '活潑', '悠閒'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>載入 word2vec model</h3>\n",
    "<pre>\n",
    "（請改用自己訓練的模型檔或下載而得的預訓練模型檔）\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(gensim.__version__)\n",
    "\n",
    "# 自訓練模型\n",
    "# model = gensim.models.Word2Vec.load('c:/python/w2v_model/cna_xin_wiki_cis180.model.bin')\n",
    "\n",
    "# TMU 預訓練模型\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('c:/python/w2v_model/y_360W_cbow_2D_300dim_2020v1.bin', unicode_errors='ignore', binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>輸入測試文句</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '不在乎天長地久，只在乎曾經擁有'\n",
    "# txt = '公平是我們追求的真理'\n",
    "# txt = '實踐是檢驗真理的唯一方法'\n",
    "# txt = '航向宇宙探索未知太空世界是每一個少年的兒時夢想'\n",
    "# txt = '上課好無趣，整天都昏昏欲睡神遊太虛'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "刪除非中文的所有文字與符號\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除非中文的所有文字與符號\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_non_chinese(line):\n",
    "    # 消除英文文數字\n",
    "    rule = re.compile('[a-zA-Z0-9]')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除特殊符號（含部分全形符號）\n",
    "    rule = re.compile('[’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除不可見字碼\n",
    "    rule = re.compile('[\\001\\002\\003\\004\\005\\006\\007\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除所有全形符號\n",
    "    rule = re.compile('[^\\u4e00-\\u9fa5]')\n",
    "    line = rule.sub(' ', line)\n",
    "    return line\n",
    "\n",
    "def remove_redundant_space(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>詞法分析（字詞修整）</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不在乎天長地久 只在乎曾經擁有\n"
     ]
    }
   ],
   "source": [
    "# 詞法分析（字詞修整）\n",
    "\n",
    "txt = remove_non_chinese(txt)\n",
    "txt = remove_redundant_space(txt)\n",
    "\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "詞法分析（斷詞、分詞）\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\trchou\\Dropbox\\000 teaching\\aisd10a\\jupyter\\unit_09_text\\unit_09_text_word_similarity_classifier\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\trchou\\AppData\\Local\\Temp\\jieba.u451fe25cd6e3a6f27d5c8b0d57922321.cache\n",
      "Loading model cost 0.906 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不在乎', '天長地久', ' ', '只在乎', '曾經', '擁有']\n"
     ]
    }
   ],
   "source": [
    "# 詞法分析（斷詞、分詞） \n",
    "\n",
    "import jieba\n",
    "\n",
    "# 有必要的話載入常用辭典\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "# 有必要的話載入專屬字典\n",
    "jieba.load_userdict('user.txt')\n",
    "\n",
    "res = jieba.cut(txt)\n",
    "\n",
    "lst = [ x for x in res ]\n",
    "\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>\n",
    "刪除虛字『的』等無用字詞（Stopword），過濾單字詞\n",
    "</h3>\n",
    "<pre>\n",
    "Stopword 代表很常見（高頻率）的詞彙，但是，對語意分辨沒有什麼貢獻。\n",
    "<p>詞法分析的最後輸出結果是<span style=\"color:red\">『字符串』（tokens）</span>，作為分類的依據\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不在乎', '天長地久', '只在乎', '曾經', '擁有']\n"
     ]
    }
   ],
   "source": [
    "# 刪除虛字『的』等無用字詞（Stopword），過濾單字詞 \n",
    "\n",
    "# stopword 可以是需要而自行增加\n",
    "stopwords = [ '的', '之', '乎', '者', '也', ' ' ]\n",
    "\n",
    "tokens = []\n",
    "for x in lst:\n",
    "    if (x not in stopwords):\n",
    "        if (len(x) >= 2):\n",
    "            tokens.append(x)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<h3>直接詞彙相似度比對</h3>\n",
    "<p>based on word2vec (word vector)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>（平均值）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剛強: 0.05947875\n",
      "真誠: 0.05890341\n",
      "苦澀: 0.05329786\n",
      "浪漫: 0.05108019\n",
      "青春: 0.04941345\n",
      "憂愁: 0.04810110\n",
      "科幻: 0.04617314\n",
      "成熟: 0.04439275\n",
      "現代: 0.04321548\n",
      "甜美: 0.04060926\n",
      "清新: 0.04026775\n",
      "冷漠: 0.03941980\n",
      "熱情: 0.03852817\n",
      "科技: 0.03419882\n",
      "悠閒: 0.03249943\n",
      "有趣: 0.02969757\n",
      "活潑: 0.02849381\n",
      "陳腐: 0.02677233\n",
      "無聊: 0.02552254\n",
      "溫和: 0.01957277\n",
      "驚悚: 0.01376841\n",
      "正義: 0.01255617\n",
      "舒服: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# 直接詞彙相似度（平均值）比對\n",
    "\n",
    "n = len(tokens)\n",
    "\n",
    "d = dict()\n",
    "for a in alst:\n",
    "    score = 0\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            # sim = model.wv.similarity(t, a)\n",
    "            sim = model.similarity(t, a)\n",
    "        except:\n",
    "            sim = 0\n",
    "        if (sim < 0):\n",
    "            sim = 0\n",
    "        score = score + sim\n",
    "    if (n == 0):\n",
    "        score = 0\n",
    "    else:\n",
    "        score = score / n\n",
    "    d[a] = score\n",
    "\n",
    "# 字典排序（成為串列）\n",
    "lst = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for a, score in lst:\n",
    "    print('%s: %10.8f' % (a, score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（最大值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真誠: 0.20308638\n",
      "浪漫: 0.19319998\n",
      "憂愁: 0.18272440\n",
      "成熟: 0.17329067\n",
      "剛強: 0.16913190\n",
      "苦澀: 0.16646215\n",
      "青春: 0.14741611\n",
      "科技: 0.14216813\n",
      "甜美: 0.12066689\n",
      "科幻: 0.11840704\n",
      "冷漠: 0.11783428\n",
      "有趣: 0.10830958\n",
      "清新: 0.10613213\n",
      "現代: 0.10499865\n",
      "活潑: 0.09939733\n",
      "溫和: 0.09786385\n",
      "熱情: 0.09003606\n",
      "無聊: 0.08784638\n",
      "陳腐: 0.08621894\n",
      "悠閒: 0.06781122\n",
      "正義: 0.06278086\n",
      "驚悚: 0.04591414\n",
      "舒服: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# 直接詞彙相似度（最大值）比對\n",
    "\n",
    "n = len(tokens)\n",
    "\n",
    "d = dict()\n",
    "for a in alst:\n",
    "    score_max = 0\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            # sim = model.wv.similarity(t, a)\n",
    "            sim = model.similarity(t, a)\n",
    "        except:\n",
    "            sim = 0\n",
    "        if (sim < 0):\n",
    "            sim = 0\n",
    "        if (sim > score_max):\n",
    "            score_max = sim\n",
    "    d[a] = score_max\n",
    "\n",
    "# 字典排序（成為串列）\n",
    "lst = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for a, score in lst:\n",
    "    print('%s: %10.8f' % (a, score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>擴展詞彙相似度比對</h3>\n",
    "<pre>\n",
    "based on word2vec (word vector)\n",
    "<span style=\"color:red\">topn=5</span>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>（平均值）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "苦澀: 0.07565614\n",
      "真誠: 0.06792980\n",
      "浪漫: 0.06718439\n",
      "憂愁: 0.06481532\n",
      "冷漠: 0.06002934\n",
      "悠閒: 0.05795810\n",
      "成熟: 0.05166683\n",
      "剛強: 0.04832403\n",
      "青春: 0.04400143\n",
      "熱情: 0.04246446\n",
      "甜美: 0.04052958\n",
      "溫和: 0.03740396\n",
      "陳腐: 0.03620513\n",
      "清新: 0.03527851\n",
      "正義: 0.03379348\n",
      "有趣: 0.03313669\n",
      "科技: 0.03078090\n",
      "活潑: 0.02878336\n",
      "無聊: 0.02807757\n",
      "現代: 0.02434960\n",
      "舒服: 0.01744028\n",
      "科幻: 0.01729825\n",
      "驚悚: 0.01413314\n"
     ]
    }
   ],
   "source": [
    "# 擴展詞彙相似度（平均值）比對\n",
    "\n",
    "ext = []\n",
    "for t0 in tokens:\n",
    "    try:\n",
    "        # lst = model.wv.most_similar(t0, topn=5)\n",
    "        lst = model.most_similar(t0, topn=5)\n",
    "    except:\n",
    "        lst = []\n",
    "    for t, _ in lst:\n",
    "        if (t not in ext):\n",
    "            ext.append(t)\n",
    "# print(ext)\n",
    "\n",
    "n = len(ext)\n",
    "\n",
    "d = dict()\n",
    "for a in alst:\n",
    "    score = 0\n",
    "    for t in ext:\n",
    "        try:\n",
    "            # sim = model.wv.similarity(t, a)\n",
    "            sim = model.similarity(t, a)\n",
    "        except:\n",
    "            sim = 0\n",
    "        if (sim < 0):\n",
    "            sim = 0\n",
    "        score = score + sim\n",
    "    if (n == 0):\n",
    "        score = 0\n",
    "    else:\n",
    "        score = score / n\n",
    "    d[a] = score\n",
    "\n",
    "# 字典排序（成為串列）\n",
    "lst = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for a, score in lst:\n",
    "    print('%s: %10.8f' % (a, score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>（最大值）</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真誠: 0.20308638\n",
      "浪漫: 0.19319998\n",
      "憂愁: 0.18272440\n",
      "成熟: 0.17329067\n",
      "剛強: 0.16913190\n",
      "苦澀: 0.16646215\n",
      "青春: 0.14741611\n",
      "科技: 0.14216813\n",
      "甜美: 0.12066689\n",
      "科幻: 0.11840704\n",
      "冷漠: 0.11783428\n",
      "有趣: 0.10830958\n",
      "清新: 0.10613213\n",
      "現代: 0.10499865\n",
      "活潑: 0.09939733\n",
      "溫和: 0.09786385\n",
      "熱情: 0.09003606\n",
      "無聊: 0.08784638\n",
      "陳腐: 0.08621894\n",
      "悠閒: 0.06781122\n",
      "正義: 0.06278086\n",
      "驚悚: 0.04591414\n",
      "舒服: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# 擴展詞彙相似度（最大值）比對\n",
    "\n",
    "ext = []\n",
    "for t0 in tokens:\n",
    "    try:\n",
    "        # lst = model.wv.most_similar(t0, topn=5)\n",
    "        lst = model.most_similar(t0, topn=5)\n",
    "    except:\n",
    "        lst = []\n",
    "    for t, _ in lst:\n",
    "        if (t not in ext):\n",
    "            ext.append(t)\n",
    "# print(ext)\n",
    "\n",
    "n = len(ext)\n",
    "\n",
    "d = dict()\n",
    "for a in alst:\n",
    "    score_max = 0\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            # sim = model.wv.similarity(t, a)\n",
    "            sim = model.similarity(t, a)\n",
    "        except:\n",
    "            sim = 0\n",
    "        if (sim < 0):\n",
    "            sim = 0\n",
    "        if (sim > score_max):\n",
    "            score_max = sim\n",
    "    d[a] = score_max\n",
    "\n",
    "# 字典排序（成為串列）\n",
    "lst = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for a, score in lst:\n",
    "    print('%s: %10.8f' % (a, score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:orange\">Text Classification based on similarity from word2vec（整合版）</h3>\n",
    "<p>擴展詞彙相似度（平均值）比對</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\trchou\\Dropbox\\000 teaching\\aisd10a\\jupyter\\unit_09_text\\unit_09_text_word_similarity_classifier\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\trchou\\AppData\\Local\\Temp\\jieba.u451fe25cd6e3a6f27d5c8b0d57922321.cache\n",
      "Loading model cost 0.929 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Text Classification based on similarity from word2vec（整合版）\n",
    "\n",
    "import gensim\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 分類類別\n",
    "\n",
    "alst = [\n",
    "    '清新', '憂愁', '真誠', '青春', '成熟',\n",
    "    '有趣', '無聊', '溫和', '剛強', '科技',\n",
    "    '熱情', '冷漠', '正義', '甜美', '苦澀',\n",
    "    '浪漫', '科幻', '現代', '陳腐', '驚悚',\n",
    "    '舒服', '活潑', '悠閒'\n",
    "]\n",
    "\n",
    "# stopword 可以是需要而自行增加\n",
    "\n",
    "stopwords = [ '的', '之', '乎', '者', '也', ' ' ]\n",
    "\n",
    "# 載入語言模型（word2vec, jieba, ...）函數定義\n",
    "\n",
    "def load_language_model():\n",
    "    # model = gensim.models.Word2Vec.load('c:/python/w2v_model/cna_xin_wiki_cis180.model.bin')\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('c:/python/w2v_model/y_360W_cbow_2D_300dim_2020v1.bin', unicode_errors='ignore', binary=True)\n",
    "    jieba.set_dictionary('dict.txt.big')\n",
    "    jieba.load_userdict('user.txt')\n",
    "    return model\n",
    "\n",
    "# 刪除非中文的所有文字與符號函數定義\n",
    "\n",
    "def remove_non_chinese(line):\n",
    "    # 消除英文文數字\n",
    "    rule = re.compile('[a-zA-Z0-9]')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除特殊符號（含部分全形符號）\n",
    "    rule = re.compile('[’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除不可見字碼\n",
    "    rule = re.compile('[\\001\\002\\003\\004\\005\\006\\007\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a]+')\n",
    "    line = rule.sub(' ', line)\n",
    "    # 消除所有全形符號\n",
    "    rule = re.compile('[^\\u4e00-\\u9fa5]')\n",
    "    line = rule.sub(' ', line)\n",
    "    return line\n",
    "\n",
    "def remove_redundant_space(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n",
    "\n",
    "# 詞法分析器函數定義\n",
    "\n",
    "def lexical_analyzer(txt):\n",
    "    # print(txt)\n",
    "    txt = remove_non_chinese(txt)\n",
    "    txt = remove_redundant_space(txt)\n",
    "    res = jieba.cut(txt)\n",
    "    lst = [ x for x in res ]\n",
    "    # print(lst)\n",
    "    tokens = []\n",
    "    for x in lst:\n",
    "        if (x not in stopwords):\n",
    "            if (len(x) >= 2):\n",
    "                tokens.append(x)\n",
    "    # print(tokens)\n",
    "    return tokens\n",
    "\n",
    "# 文件分類器函數定義\n",
    "\n",
    "def text_classifier(tokens):\n",
    "    # 擴展詞彙\n",
    "    ext = []\n",
    "    for t0 in tokens:\n",
    "        try:\n",
    "            # lst = model.wv.most_similar(t0, topn=5)\n",
    "            lst = model.most_similar(t0, topn=5)\n",
    "        except:\n",
    "            lst = []\n",
    "        for t, _ in lst:\n",
    "            if (t not in ext):\n",
    "                ext.append(t)\n",
    "    # print(ext)\n",
    "    # 分類\n",
    "    n = len(ext)\n",
    "    d = dict()\n",
    "    for a in alst:\n",
    "        score = 0\n",
    "        for t in ext:\n",
    "            try:\n",
    "                # sim = model.wv.similarity(t, a)\n",
    "                sim = model.similarity(t, a)\n",
    "            except:\n",
    "                sim = 0\n",
    "            if (sim < 0):\n",
    "                sim = 0\n",
    "            score = score + sim\n",
    "        if (n == 0):\n",
    "            score = 0\n",
    "        else:\n",
    "            score = score / n\n",
    "        d[a] = score\n",
    "    # 字典排序（成為串列）\n",
    "    lst = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "    return lst\n",
    "\n",
    "# 載入語言模型\n",
    "\n",
    "model = load_language_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>整合測試</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不在乎天長地久，只在乎曾經擁有\n",
      "苦澀: 0.07565614\n",
      "真誠: 0.06792980\n",
      "浪漫: 0.06718439\n",
      "憂愁: 0.06481532\n",
      "冷漠: 0.06002934\n",
      "悠閒: 0.05795810\n",
      "成熟: 0.05166683\n",
      "剛強: 0.04832403\n",
      "青春: 0.04400143\n",
      "熱情: 0.04246446\n",
      "甜美: 0.04052958\n",
      "溫和: 0.03740396\n",
      "陳腐: 0.03620513\n",
      "清新: 0.03527851\n",
      "正義: 0.03379348\n",
      "有趣: 0.03313669\n",
      "科技: 0.03078090\n",
      "活潑: 0.02878336\n",
      "無聊: 0.02807757\n",
      "現代: 0.02434960\n",
      "舒服: 0.01744028\n",
      "科幻: 0.01729825\n",
      "驚悚: 0.01413314\n"
     ]
    }
   ],
   "source": [
    "# 整合測試\n",
    "\n",
    "# 輸入\n",
    "\n",
    "# 測試例句\n",
    "txt = '不在乎天長地久，只在乎曾經擁有'\n",
    "# txt = '實踐是檢驗真理的唯一方法。'\n",
    "# txt = '在新的一年裡，希望所有朋友都幸福快樂心想事成！'\n",
    "\n",
    "# 文件分類\n",
    "\n",
    "tokens = lexical_analyzer(txt)\n",
    "result = text_classifier(tokens)\n",
    "\n",
    "# 顯示結果\n",
    "\n",
    "print(txt)\n",
    "for a, score in result:\n",
    "    print('%s: %10.8f' % (a, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
